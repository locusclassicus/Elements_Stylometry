Smarket.2005 = Smarket[!train,]
dim(Smarket.2005)
glm.fit = glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = Smarket, family = binomial, subset = train)
glm.probs = predict(glm.fit, Smarket.2005, type = "response")
glm.pred = rep("Down", 252)
glm.pred[glm.probs > 0.5] = "Up"
table(glm.pred, Direction.2005)
table(glm.pred, Smarket.2005$Direction)
mean(glm.pred == Smarket.2005$Direction)
library(MASS)
lda.fit = lda(Direction ~ Lag1 + Lag2, data = Smarket, subset = train)
lda.fit
plot(lda.fit)
lda.predict = predict(lda.fit, Smarket.2005)
names(lda.pred)
names(lda.predict)
lda.class = lda.predict$class
table(lda.class, Smarket.2005$Direction)
mean(lda.class == Direction.2005)
mean(lda.class == Smarket.2005$Direction)
load("/Users/olga/R_Workflow/CountingPlato/data/platoDialogue.RData")
load("/Users/olga/R_Workflow/CountingPlato/data/my_freq.Rdata")
View(my_freq)
View(platoDialogue)
platoDialogue <- cbind(platoDialogue, my_freq[, c("ἐγώ", "φημί")])
colnames(platoDialogue)
colnames(platoDialogue) <- c("dialogue", "pages",    "direct",   "narrated", "meanSL",    "ratio",    "type",  "ego",    "pemi")
colnames(platoDialogue) <- c("dialogue", "pages",    "direct",   "narrated", "meanSL",    "ratio",    "type",  "ego",    "phemi")
plot(phemi ~ type, data = platoDialogue)
glm.fit <- glm(type ~ ego + phemi, data = platoDialogue)
class(platoDialogue$type)
glm.fit <- glm(type ~ ego + phemi, data = platoDialogue, family = binomial)
glm.fit
anova(glm.fit)
coef(glm.fit)
contrast(platoDialogue$type)
contrasts(platoDialogue$type)
plot(ego ~ type, data = platoDialogue)
summary(glm.fit)
glm.probs = predict(glm.fit, type = "response")
range(glm.probs)
eval(range(glm.probs))
eval(5.170696e-10)
5.170696e-10
as.integer(5.170696e-10)
as.integer(1.000000e+00)
glm.pred = rep("Direct", 46)
glm.pred[glm.probs > 0.5] = "Narrated"
table(glm.pred, platoDialogue$type)
(16+28)/46
mean(glm.pred == platoDialogue$type)
glm.pred == platoDialogue$type
glm.pred
platoDialogue$type
glm.pred = rep("direct", 46)
glm.pred[glm.probs > 0.5] = "narrated"
mean(glm.pred == platoDialogue$type)
glm.fit <- glm(type ~ phemi, data = platoDialogue, family = binomial)
glm.pred = rep("direct", 46)
glm.pred[glm.probs > 0.5] = "narrated"
table(glm.pred, platoDialogue$type)
glm.fit <- glm(type ~ ego, data = platoDialogue, family = binomial)
glm.pred = rep("direct", 46)
glm.pred[glm.probs > 0.5] = "narrated"
table(glm.pred, platoDialogue$type)
summary(glm.fit)
lda.fit <- lda(type ~ ego + phemi, data = platoDialogue)
lda.fit
lda.pred = predict(lda.fit, platoDialogue)
lda.class = lda.pred$class
table(lda.class, platoDialogue$type)
)
mean(lda.class == platoDialogue$type)
qda.fit <- qda(type ~ ego + phemi, data = platoDialogue)
qda.pred = predict(qda.fit, platoDialogue)
qda.class = qda.pred$class
table(qda.class, platoDialogue$type)
mean(qda.class == platoDialogue$type)
library(class)
set.seed(1)
sample.int(46, 23)
train = sample.int(46, 23)
train.X = cbind(ego, phemi)[train, ]
attach(platoDialogue)
train.X = cbind(ego, phemi)[train, ]
train.X
train.type = type[train]
knn.pred = knn(train.X, test.X, train.type, k = 1)
test.X = cbind(ego, phemi)[!train, ]
train.type = type[train]
knn.pred = knn(train.X, test.X, train.type, k = 1)
table(knn.pred, type)
table(knn.pred, platoDialogue$type)
length(knn.pred)
test.X
train.X
attach(platoDialogue)
test.X = cbind(ego, phemi)[!train, ]
View(test.X)
library(class)
set.seed(1)
attach(platoDialogue)
train = sample.int(46, 23)
train.X = cbind(ego, phemi)[train, ]
test.X = cbind(ego, phemi)[!train, ]
train.type = type[train]
knn.pred = knn(train.X, test.X, train.type, k = 1)
table(knn.pred, train.type)
attach(platoDialogue)
set.seed(1)
train = sample.int(46, 23)
train.X = cbind(ego, phemi)[train, ]
test.X = cbind(ego, phemi)[!train, ]
test.X = cbind(platoDialogue$ego, platoDialogue$phemi)[!train, ]
View(train.X)
train.type = type[train]
train.type
test.X = cbind(ego, phemi)[-train, ]
View(test.X)
View(train.X)
knn.pred = knn(train.X, test.X, train.type, k = 1)
table(knn.pred, type)
knn(train.X, test.X, train.type, k = 1)
cm = as.matrix(table(Actual = train.type, Predicted = knn.pred))
cm
sum(diag(cm))/length(cl)
table(knn.pred, train.type)
mean(knn.pred == train.type)
knn.pred = knn(train.X, test.X, train.type, k = 3)
table(knn.pred, train.type)
mean(knn.pred == train.type)
mean(knn.pred == train.type)
anova(glm.fit)
glm.fit <- glm(type ~ ego + phemi, data = platoDialogue, family = binomial)
anova(glm.fit)
anova(glm.fit, test = "Chisq")
glm.fit$fitted.values
newdat <- data.frame(cut.phemi=seq(min(platoDialogue$phemi), max(platoDialogue$phemi),len=100))
newdat
newdat <- data.frame(cut.phemi=seq(min(platoDialogue$phemi), max(platoDialogue$phemi),len=46))
newdat
newdat$pred = predict(glm.fit, newdata=newdat, type="response")
newdat
newdat$pred = order(predict(glm.fit, newdata=newdat, type="response"))
newdat
newdat$pred = sort(predict(glm.fit, newdata=newdat, type="response"))
newdat
plot(phemi~pred, data=newdat, col="red4")
plot_logistic_curve = function(log_mod){
mod_frame = model.frame(log_mod)
var_names = names(mod_frame)
newdat = setNames(data.frame(seq(min(mod_frame[[2]]), max(mod_frame[[2]]), len=100)), var_names[2])
newdat[var_names[1]] = predict(log_mod, newdata = newdat, type="response")
plot(mod_frame[[1]] ~ mod_frame[[2]], col = "red4", xlab = var_names[[2]], ylab = var_names[[1]])
lines(newdat[[var_names[2]]], newdat[[var_names[1]]], col = "green4", lwd = 2)
}
plot_logistic_curve(glm.fit)
model(glm.fit)
model.frame(glm.fit)
var_names = names(mod_frame)
var_names = names(model.frame(glm.fit))
newdat = setNames(data.frame(seq(min(mod_frame[[2]]), max(mod_frame[[2]]), len=100)), var_names[2])
mod.frame = model.frame(glm.fit)
newdat = setNames(data.frame(seq(min(mod_frame[[2]]), max(mod_frame[[2]]), len=100)), var_names[2])
mod_frame = model.frame(glm.fit)
newdat = setNames(data.frame(seq(min(mod_frame[[2]]), max(mod_frame[[2]]), len=100)), var_names[2])
newdat[var_names[1]] = predict(log_mod, newdata = newdat, type="response")
newdat[var_names[1]] = predict(glm.fit, newdata = newdat, type="response")
View(newdat)
newdat = setNames(data.frame(seq(min(mod_frame[[2]]), max(mod_frame[[2]]), len=46)), var_names[2])
newdat[var_names[1]] = predict(log_mod, newdata = newdat, type="response")
newdat[var_names[1]] = predict(glm.mod, newdata = newdat, type="response")
newdat[var_names[1]] = predict(glm.fit, newdata = newdat, type="response")
plot(mod_frame[[1]] ~ mod_frame[[2]], col = "red4", xlab = var_names[[2]], ylab = var_names[[1]])
lines(newdat[[var_names[2]]], newdat[[var_names[1]]], col = "green4", lwd = 2)
glm.fit <- glm(type ~ phemi, data = platoDialogue, family = binomial)
plot_logistic_curve = function(log_mod){
mod_frame = model.frame(log_mod)
var_names = names(mod_frame)
newdat = setNames(data.frame(seq(min(mod_frame[[2]]), max(mod_frame[[2]]), len=46)), var_names[2])
newdat[var_names[1]] = predict(log_mod, newdata = newdat, type="response")
plot(mod_frame[[1]] ~ mod_frame[[2]], col = "red4", xlab = var_names[[2]], ylab = var_names[[1]])
lines(newdat[[var_names[2]]], newdat[[var_names[1]]], col = "green4", lwd = 2)
}
plot_logistic_curve(glm.fit)
plot(mod_frame[[1]] ~ mod_frame[[2]],  xlab = var_names[[2]], ylab = var_names[[1]])
mod_frame = model.frame(glm.fit)
var_names = names(mod_frame)
newdat = setNames(data.frame(seq(min(mod_frame[[2]]), max(mod_frame[[2]]), len=46)), var_names[2])
newdat[var_names[1]] = predict(log_mod, newdata = newdat, type="response")
newdat[var_names[1]] = predict(glm.fit, newdata = newdat, type="response")
plot(mod_frame[[1]] ~ mod_frame[[2]], col = "red4", xlab = var_names[[2]], ylab = var_names[[1]])
max(platoDialogue$phemi)
xval <-seq(0, 2.3, 0.01)
yval <- predict(glm.fit, type="response")
mean(glm.pred == platoDialogue$type)
which(glm.pred != platoDialogue$type)
table(glm.pred, platoDialogue$type)
decisionplot(qda.fit, platoDialogue, class = "type")
library(MASS)
decisionplot(qda.fit, platoDialogue, class = "type")
decisionplot <- function(model, data, class = NULL, predict_type = "class",
resolution = 100, showgrid = TRUE, ...) {
if(!is.null(class)) cl <- data[,class] else cl <- 1
data <- data[,1:2]
k <- length(unique(cl))
plot(data, col = as.integer(cl)+1L, pch = as.integer(cl)+1L, ...)
# make grid
r <- sapply(data, range, na.rm = TRUE)
xs <- seq(r[1,1], r[2,1], length.out = resolution)
ys <- seq(r[1,2], r[2,2], length.out = resolution)
g <- cbind(rep(xs, each=resolution), rep(ys, time = resolution))
colnames(g) <- colnames(r)
g <- as.data.frame(g)
### guess how to get class labels from predict
### (unfortunately not very consistent between models)
p <- predict(model, g, type = predict_type)
if(is.list(p)) p <- p$class
p <- as.factor(p)
if(showgrid) points(g, col = as.integer(p)+1L, pch = ".")
z <- matrix(as.integer(p), nrow = resolution, byrow = TRUE)
contour(xs, ys, z, add = TRUE, drawlabels = FALSE,
lwd = 2, levels = (1:(k-1))+.5)
invisible(z)
}
source("~/R_Workflow/DecisionPlot.R")
decisionplot(qda.fit, platoDialogue, class = "type")
decisionplot(qda.fit, platoDialogue, class = "type")
decisionplot(qda.fit, platoDialogue)
decisionplot_ggplot <- function(model, data, class = NULL, predict_type = "class",
resolution = 100, showgrid = TRUE, ...) {
if(!is.null(class)) cl <- data[,class] else cl <- 1
data <- data[,1:2]
cn <- colnames(data)
k <- length(unique(cl))
data$pch <- data$col <- as.integer(cl) + 1L
gg <- ggplot(aes_string(cn[1], cn[2]), data = data) +
geom_point(aes_string(col = 'as.factor(col)', shape = 'as.factor(col)'), size = 3)
# make grid
r <- sapply(data[, 1:2], range, na.rm = TRUE)
xs <- seq(r[1, 1], r[2, 1], length.out = resolution)
ys <- seq(r[1, 2], r[2, 2], length.out = resolution)
g <- cbind(rep(xs, each = resolution),
rep(ys, time = resolution))
colnames(g) <- colnames(r)
g <- as.data.frame(g)
### guess how to get class labels from predict
### (unfortunately not very consistent between models)
p <- predict(model, g, type = predict_type)
if(is.list(p)) p <- p$class
g$col <- g$pch <- as.integer(as.factor(p)) + 1L
if(showgrid)
gg <- gg + geom_point(aes_string(x = cn[1], y = cn[2], col = 'as.factor(col)'), data = g, shape = 20, size = 1)
gg + geom_contour(aes_string(x = cn[1], y = cn[2], z = 'col'), data = g, inherit.aes = FALSE)
}
decisionplot(qda.fit, platoDialogue)
library(klaR)
partimat(type ~ ego + phemi, data = platoDialogue, method="qda")
install.packages("klaR")
library(klaR)
library(klaR)
partimat(type ~ ego + phemi, data = platoDialogue, method="qda")
partimat(type ~ ego + phemi, data = platoDialogue, method="lda")
partimat(type ~ ego + phemi, data = platoDialogue, method="naiveBayes")
partimat(type ~ ego + phemi, data = platoDialogue, method="sknn")
library(klaR)
partimat(type ~ ego + phemi, data = platoDialogue, method="qda")
partimat(type ~ ego + phemi, data = platoDialogue, method="qda")
partimat(type ~ ego + phemi, data = platoDialogue, method="lda")
partimat(type ~ ego + phemi, data = platoDialogue, method="qda")
which(qda.class != platoDialogue$type)
qda.fit <- qda(type ~ ego + phemi, data = platoDialogue)
qda.fit
anova(qda.fit)
library(ISLR)
set.seed(2)
train = sample(392, 196)
lm.fit = lm(mpg ~ horsepower, data = Auto, subset = train)
attach(Auto)
lm.pred <- predict(lm.fit, Auto)
(mpg - lm.pred[-train])^2
mean((mpg - lm.pred[-train])^2)
mean(mpg - lm.pred[-train])
(mean(mpg - lm.pred[-train]))^2
mean((mpg - predict(lm.fit, Auto))[-train]^2)
(mpg - predict(lm.fit, Auto))[-train]^2
mean((mpg - lm.pred)[-train]^2)
lm.fit2 = lm(mpg ~ poly(horsepower, 2), data = Auto, subset = train)
mean((mpg - predict(lm.fit2, Auto))[-train]^2)
lm.fit3 = lm(mpg ~ poly(horsepower, 3), data = Auto, subset = train)
mean((mpg - predict(lm.fit3, Auto))[-train]^2)
library(boot)
glm.fit = glm(mpg ~ horsepower, data = Auto)
cv.err = cv.glm(Auto, glm.fit)
cv.err$delta
cv.error = rep(0, 5)
for(i in 1:5){}
for(i in 1:5){
glm.fit = glm(mpg ~ poly(horsepower, i), data = Auto)
cv.error[i] = cv.glm(Auto, glm.fit)$delta[1]
}
cv.error
set.seed(3)
cv.error.10 = rep(0, 10)
for(i in 1:10){}
for(i in 1:10){
glm.fit = glm(mpg ~ poly(horsepower, i), data = Auto)
cv.error.10[i] = cv.glm(Auto, glm.fit, K = 10)$delta[1]}
cv.error.10
x = rnorm(10)
var(x)
y = 2x
y = 2*x
var(y)
plot(y)
cov(x, y)
cor(y, x)
cor(x, y)
cov(x, y)
mean((x-mean(x))*(y-mean(y)))
var(x)
var(y)
var(x * y)
cov(x, y)
mean(x-mean(x))
mean(y-mean(y))
mean(x-mean(x))*mean((y-mean(y))
mean(x-mean(x))*mean(y-mean(y))
sum((x-mean(x))*(y-mean(y)))
(sum((x-mean(x))*(y-mean(y))))10
(sum((x-mean(x))*(y-mean(y)))/10
(sum((x-mean(x))*(y-mean(y))))/10
cov(x, y)
covariance(x, y)
cor(x, y)
xdev <- x - mean(x)
ydev <- y - mean(y)
xdev_ydev <- xdev * ydev
xdev_ydev
sum_xdev_ydev <- sum(xdev_ydev)
cov_xy <- sum_xdev_ydev / 9
cov_xy
y = -2*x
cov(x, y)
data("Portfolio")
alpha.fn = function(data, index){}
alpha.fn = function(data, index){
X = data$X[index]
Y = data$Y[index]
return((var(Y)-cov(X, Y))/var(X)+var(Y)-2*cov(X, Y)))
return((var(Y)-cov(X, Y))/var(X)+var(Y)-2*cov(X, Y))
alpha.fn = function(data, index){
X = data$X[index]
Y = data$Y[index]
return((var(Y)-cov(X, Y))/var(X)+var(Y)-2*cov(X, Y))
}
View(Portfolio)
alpha.fn(Portfolio, 1:100)
alpha.fn(Portfolio, 100)
alpha.fn(Portfolio, 99:100)
set.seed(1)
alpha.fn(Portfolio, sample(100, 100, replace = TRUE))
sample(100, 100, replace = TRUE)
boot(Portfolio, alpha.ph, R = 1000)
boot(Portfolio, alpha.fn, R = 1000)
res <- boot(Portfolio, alpha.fn, R = 1000)
View(res)
res$t
mean(res$t)
mean(res$t) - res$t0
res$t0
auto.lm <- lm(mpg ~ horsepower, data = Auto)
auto.lm
summary(auto.lm)
glm.fit
lm.fit
summary(lm.fit)
View(auto.lm)
summary(auto.lm)
glm.fit <- glm(formula = mpg ~ poly(horsepower, 2), data = Auto)
glm.fit
logLik(glm.fit)
aic(glm.fit)
AIC(glm.fit)
BIC(glm.fit)
glm.fit2 <- glm(formula = mpg ~ poly(horsepower, 2), data = Auto)
glm.fit1 <- glm(formula = mpg ~ poly(horsepower, 1), data = Auto)
AIC(glm.fit1)
AIC(glm.fit2)
AIC(glm(mpg ~ . , data = AUTO)
)
AIC(glm(mpg ~ . , data = Auto))
glm.fit1
summary(glm.fit1)
1 - pchisq(9385.9, 390)
1 - pchisq(23819, 391)
1 - pchisq((23819-9385.9), (391-390))
anova(glm.fit2, test = "Chisq")
plot(Auto$mpg ~ predict(Auto, type = "response"))
plot(Auto$mpg ~ predict(glm.fit2, type = "response"))
library(ISLR)
data("Hitters")
?fix()
names(Hitters)
Hitters = na.omit(Hitters)
library(leaps)
regfit.full = regsubsets(Salary ~ . , Hitters)
summary(regfit.full)
summary(regfit.full)
reg.summary = summary(regfit.full)
names(reg.summary)
reg.summary$rsq
reg.summary$bic
par(mfrow = c(2,2))
plot(reg.summary$rss, xlab = "Number of variables", ylab = "RSS", type = "l")
plot(reg.summary$adjr2, xlab = "Number of variables", ylab = "Adjusted RSq", type = "l")
which.max(reg.summary$adjr2)
points(8, reg.summary$adjr2[8], col = "red", cex = 2, pch = 20)
plot(reg.summary$cp, xlab = "Number of variables", ylab = "Cp", type = "l")
plot(reg.summary$bic, xlab = "Number of variables", ylab = "bic", type = "l")
plot(regfit.full, scale = "r2")
plot(regfit.full, scale = "adjr2")
plot(regfit.full, scale = "Cp")
plot(regfit.full, scale = "bic")
regfit.fwd = regsubsets(Salary ~ ., data = Hitters, nvmax = 19, method = "forward")
summary(regfit.fwd)
regfit.bwd = regsubsets(Salary ~ ., data = Hitters, nvmax = 19, method = "backward")
plot(regfit.fwd, scale = "bic")
par(mfrow = c(1, 1))
plot(regfit.fwd, scale = "bic")
set.seed(1)
train = sample(c(TRUE, FALSE), nrow(Hitters), rep = TRUE)
train
nrow(Hitters)
nrow(train)
length(train)
sum(train)
263-134
test = (!train)
head(train)
head(test)
regfit.best = regsubsets(Salary ~ ., data = Hitters[train,], nvmax = 19)
test.mat = model.matrix(Salary ~ ., data = Hitters[test,])
View(test.mat)
nrow(test.mat)
?model.matrix()
coef(regfit.bwd, id = 1)
coef(regfit.bwd, id = 2)
coef(regfit.bwd, id = 3)
coef(regfit.bwd, id = 4)
val.error = rep(NA, 19)
for (i in 1:19){
coefi = coef(regfit.best, id = i)
pred = test.mat[,names(coefi)]%*%coefficients()
for (i in 1:19){
coefi = coef(regfit.best, id = i)
pred = test.mat[,names(coefi)]%*%coeffi
val.errors[i] = mean((Hitters$Salary[test] - pred)^2)
}
for (i in 1:19){
coefi = coef(regfit.best, id = i)
pred = test.mat[,names(coefi)]%*%coefi
val.errors[i] = mean((Hitters$Salary[test] - pred)^2)
}
val.errors = rep(NA, 19)
for (i in 1:19){
coefi = coef(regfit.best, id = i)
pred = test.mat[,names(coefi)]%*%coefi
val.errors = rep(NA, 19)
}
val.errors = rep(NA, 19)
for (i in 1:19){
coefi = coef(regfit.best, id = i)
pred = test.mat[,names(coefi)]%*%coefi
val.errors[i] = rep(NA, 19)
}
warnings()
val.errors = rep(NA, 19)
for (i in 1:19){
coefi = coef(regfit.best, id = i)
pred = test.mat[,names(coefi)]%*%coefi
val.errors[i] = mean((Hitters$Salary[test] - pred)^2)
}
which.min(val.errors)
View(Hitters)
summary(Hitters)
summary(test.mat)
coefi = coef(regfit.best, id = 2)
coefi
head(test.mat[,names(coefi)])
test.mat[,names(coefi)]%*%coefi
model.matrix(regfit.best)
matrix(regfit.best)
load("/Users/olga/R_Workflow/CountingPlato/data/platoDialogue.RData")
model.matrix(platoDialogue)
model.matrix(type ~ ratio, data = platoDialogue)
contrasts(model.matrix(type ~ ratio, data = platoDialogue))
View(platoDialogue)
contrasts(model.matrix(meanSL ~ ratio, data = platoDialogue))
model.matrix(meanSL ~ ratio, data = platoDialogue)
load("/Users/olga/R_Workflow/GreekImpostors/data/my_corpus.Rdata")
GreekCorp <- make.table.of.frequencies(my_corpus, relative = TRUE, absent.sensitive = FALSE, features = make.frequency.list(my_corpus))
dim(GreekCorp)
library(stylo)
GreekCorp <- make.table.of.frequencies(my_corpus, relative = TRUE, absent.sensitive = FALSE, features = make.frequency.list(my_corpus))
dim(GreekCorp)
GreekCorp <- as.data.frame.matrix(as.table(GreekCorp))
my_text_to_be_tested = as.matrix(GreekCorp[c(1),])
my_frequency_table = as.matrix(GreekCorp[-c(1),])
imposters(reference.set = my_frequency_table, test = my_text_to_be_tested, candidate.set = NULL)
setwd("~/R_Workflow/Stylometry")
View(my_text_to_be_tested)
